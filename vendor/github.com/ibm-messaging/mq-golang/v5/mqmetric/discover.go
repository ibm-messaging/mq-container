/*
Package mqmetric contains a set of routines common to several
commands used to export MQ metrics to different backend
storage mechanisms including Prometheus and InfluxDB.
*/
package mqmetric

/*
  Copyright (c) IBM Corporation 2016, 2025

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.

   Contributors:
     Mark Taylor - Initial Contribution
*/

/*
Functions in this file discover the data available from a queue manager
via the MQ V9 pub/sub monitoring feature. Each metric (element) is
found by discovering the types of metric, and the types are found by first
discovering the classes. Sample program amqsrua is shipped with MQ V9 to
give a good demonstration of the process, which is followed here.
*/

import (
	"bufio"
	"fmt"
	"os"
	"strings"
	"unicode/utf8"

	"github.com/ibm-messaging/mq-golang/v5/ibmmq"
)

// MonElement describes the real metric element generated by MQ
type MonElement struct {
	Parent         *MonType
	Description    string // An English phrase describing the element
	DescriptionNLS string // A translated phrase for the current locale
	MetricName     string // Reformatted description suitable as label
	Datatype       int32
	Values         map[string]int64
}

// MonType describes the "types" of data generated by MQ. Each class generates
// one or more type of data such as OPENCLOSE (from STATMQI class) or
// LOG (from DISK class)
type MonType struct {
	Parent       *MonClass
	Name         string
	Description  string
	ObjectTopic  string // topic for actual data responses
	elementTopic string // discovery of elements
	Elements     map[int]*MonElement
	subHobj      map[string]*MQTopicDescriptor
}

// MonClass described the "classes" of data generated by MQ, such as DISK and CPU
type MonClass struct {
	Parent      *AllMetrics
	Name        string
	Description string
	typesTopic  string
	flags       int
	Types       map[int]*MonType
}

// The AllMetrics structure is the top of the tree, holding the set of classes.
type AllMetrics struct {
	Classes map[int]*MonClass
}

// This structure contains additional info about any object type that may need to be held.
// The first fields are used for all object types. Following fields will apply to different
// object types.
type ObjInfo struct {
	exists          bool // Used during rediscovery
	firstCollection bool // To indicate discard needed of first stat
	Description     string
	// Qmgr attributes
	QMgrName string
	HostName string
	// These are used for queue information
	AttrMaxDepth int64  // The queue attribute value. Not the max depth reported by RESET QSTATS
	AttrUsage    int64  // Normal or XMITQ
	DefType      int64  // Predefined or temp/perm dynamic queue
	Cluster      string // The name of a single cluster in which the queue is shared (CLUSTERNL not supported here)
	// Some channel information
	AttrMaxInst  int64
	AttrMaxInstC int64
	AttrCurInst  int64 // Currently active instances of this channel - would only work if "jobname" disabled
	AttrChlType  int64
}

// QMgrMapKey can never be a real object name and is therefore useful in
// maps that may contain only this single entry
const QMgrMapKey = "@self"
const NativeHAKeyPrefix = "@NATIVEHA@"
const ClassNameQ = "STATQ"

const maxBufSize = 100 * 1024 * 1024 // 100 MB

const defaultMaxQDepth = 5000

var qInfoMap map[string]*ObjInfo   // These maps probably need to be moved into the ci.si structures but at least they
var chlInfoMap map[string]*ObjInfo // are not public interface elements
var amqpInfoMap map[string]*ObjInfo
var qMgrInfo = new(ObjInfo)
var nhaInfoMap map[string]*ObjInfo

var locale string

func GetDiscoveredQueues() []string {
	traceEntry("GetDiscoveredQueues")
	keys := make([]string, 0)
	for key := range qInfoMap {
		keys = append(keys, key)
	}
	traceExit("GetDiscoveredQueues", 0)
	return keys
}

func GetProcessPublicationCount() int {
	ci := getConnection(GetConnectionKey())
	return ci.publicationCount
}

/*
 * A collector can set the locale (eg "Fr_FR") before doing the discovery
 * process to get access to the MQ-translated strings
 */
func SetLocale(l string) {
	locale = l
}

/*
 * Check any important parameters  - this must be called after DiscoverAndSubscribe
 * to maintain compatibility of the package's APIs.  It also needs the list of queues to have been
 * populated first which is also done in DiscoverAndSubscribe.
 * Returns: an MQ CompCode, error string. CompCode can be MQCC_OK, WARNING or ERROR.
 */
func VerifyConfig() (int32, error) {
	var err error
	var v map[int32]interface{}
	var compCode = ibmmq.MQCC_OK

	traceEntry("VerifyConfig")
	ci := getConnection(GetConnectionKey())
	if !ci.discoveryDone {
		err = fmt.Errorf("Error: Need to call DiscoverAndSubscribe first")
		compCode = ibmmq.MQCC_FAILED
	}

	if err == nil {
		selectors := []int32{ibmmq.MQIA_MAX_Q_DEPTH, ibmmq.MQIA_DEFINITION_TYPE}
		v, err = ci.si.replyQObj.Inq(selectors)
		if err == nil {
			maxQDepth := v[ibmmq.MQIA_MAX_Q_DEPTH].(int32)
			// Function has tuning based on number of queues to be monitored
			// Current published resource topics are approx 16 subs for 95 elements on the qmgr
			// ... and 35 elements per queue in 4 subs
			// Round these to 20 and 5 for a bit of headroom
			// Make recommended minimum qdepth  60 / 10 * total per interval to allow one minute of data
			// as MQ publications are at 10 second interval by default (and no public tuning)
			// and assume monitor collection interval is one minute
			// Since we don't do pubsub-based collection on z/OS, this qdepth doesn't matter
			recommendedDepth := (20 + len(qInfoMap)*5) * 6
			if maxQDepth < int32(recommendedDepth) && ci.usePublications {
				err = fmt.Errorf("Warning: Maximum queue depth on %s may be too low. Current value = %d. Suggested depth based on queue count is at least %d", ci.si.replyQBaseName, maxQDepth, recommendedDepth)
				compCode = ibmmq.MQCC_WARNING
			}

			// There may also be a high number of channels that meet the selection criteria. Make sure we've got enough space
			// for a DIS CHS(*) in case that pattern is used. I've added a small bit of headroom but we will normally only get
			// exactly the number of responses to match the number of actual channels. Of course, that number may change in the
			// lifetime of the system but we only check what's possible at startup.If the channels are being named via a set of
			// separate patterns, then this will overestimate what's needed. Hence it's a warning, not an error.
			recommendedDepth = len(chlInfoMap) + 20
			if maxQDepth < int32(recommendedDepth) && len(chlInfoMap) > 0 {
				err = fmt.Errorf("Warning: Maximum queue depth on %s may be too low. Current value = %d. Suggested depth based on channel count is at least %d\n", ci.si.replyQBaseName, maxQDepth, recommendedDepth)
				compCode = ibmmq.MQCC_WARNING
			}

			// Make sure this reply queue that has been opened is not a predefined queue, so it
			// has come from a model definition. The base replyQ is opened twice for different reasons.
			// A LOCAL queue would end up with mixed sets of replies/publications.
			// This test is bypassed if 2 different reply queue names are configured.
			if ci.si.replyQ2BaseName == "" || ci.si.replyQ2BaseName == ci.si.replyQBaseName {
				defType := v[ibmmq.MQIA_DEFINITION_TYPE].(int32)
				if defType == ibmmq.MQQDT_PREDEFINED {
					err = fmt.Errorf("Error: ReplyQ parameter %s must refer to a MODEL queue,", ci.si.replyQBaseName)
					compCode = ibmmq.MQCC_FAILED
				}
			}
		}
	}

	traceExitErr("VerifyConfig", 0, err)

	return compCode, err
}

/*
DiscoverAndSubscribe does the work of finding the
different resources available from a queue manager and
issuing the MQSUB calls to collect the data
*/
func DiscoverAndSubscribe(dc DiscoverConfig) error {
	traceEntry("DiscoverAndSubscribe")
	ci := getConnection(GetConnectionKey())
	ci.discoveryDone = true
	redo := false

	qInfoMap = make(map[string]*ObjInfo)
	nhaInfoMap = make(map[string]*ObjInfo)
	nhaInfoElem := new(ObjInfo)
	nhaInfoElem.exists = true
	nhaInfoMap["#"] = nhaInfoElem

	err := discoverAndSubscribe(dc, redo)

	traceExitErr("DiscoverAndSubscribe", 0, err)
	return err
}
func RediscoverAndSubscribe(dc DiscoverConfig) error {
	traceEntry("RediscoverAndSubscribe")

	ci := getConnection(GetConnectionKey())
	ci.discoveryDone = true
	redo := true

	// Assume queues have been deleted and we will tidy up later.
	// The flag is reset to true during the discovery process if the queue still exists
	for _, qi := range qInfoMap {
		qi.exists = false
	}

	err := discoverAndSubscribe(dc, redo)

	// We now know if an object still exists; remove it from the map if not.
	for key, qi := range qInfoMap {
		if !qi.exists {
			delete(qInfoMap, key)
		}
	}

	traceExitErr("RediscoverAndSubscribe", 0, err)

	return err
}

func RediscoverAttributes(objectType int32, objectPatterns string) error {
	var err error
	var infoMap map[string](*ObjInfo)
	var fn func(string, map[string](*ObjInfo)) error

	traceEntry("RediscoverAttributes")
	switch objectType {
	case ibmmq.MQOT_CHANNEL:
		// Always start with a clean slate for these maps
		chlInfoMap = make(map[string]*ObjInfo)
		infoMap = chlInfoMap
		fn = inquireChannelAttributes
	case OT_CHANNEL_AMQP:
		// Always start with a clean slate for these maps
		amqpInfoMap = make(map[string]*ObjInfo)
		infoMap = amqpInfoMap
		fn = inquireAMQPChannelAttributes
	default:
		err = fmt.Errorf("Unsupported object type: %d", objectType)
	}

	if err == nil {
		err = fn(objectPatterns, infoMap)

		for key, oi := range infoMap {
			if !oi.exists {
				delete(infoMap, key)
			}
		}
	}

	traceExitErr("RediscoverAttributes", 0, err)

	return err
}

func discoverAndSubscribe(dc DiscoverConfig, redo bool) error {
	var err error

	traceEntry("discoverAndSubscribe")
	ci := getConnection(GetConnectionKey())

	// What metrics can the queue manager provide?
	if err == nil && !redo {
		err = discoverStats(dc)
	}

	// Which queues have we been asked to monitor? Expand wildcards
	// to explicit names so that subscriptions work.
	if err == nil {
		if dc.MonitoredQueues.UseWildcard {
			err = discoverQueues(dc.MonitoredQueues.ObjectNames)
		} else {
			qList := strings.Split(dc.MonitoredQueues.ObjectNames, ",")
			// Make sure the names are reasonably valid
			for i := 0; i < len(qList); i++ {
				key := strings.TrimSpace(qList[i])
				qInfoMap[key] = new(ObjInfo)
			}
		}

	}

	if err == nil {
		// Recommended handles are based on the number of MQSUB calls we make - as above when checking for maxQDepth
		// we round up the number of qmgr subs and per-queue subs. This will need extension if more object types are supported
		// in the amqsrua-style of resource subscriptions. Add a few extra just in case.
		// We can ignore this check when we're using durable subscriptions for the queue info - the default of 256 will
		// be plenty.
		if ci.durableSubPrefix == "" {
			recommendedHandles := 20 + len(qInfoMap)*5 + 10
			if ci.si.maxHandles < int32(recommendedHandles) && ci.usePublications {
				err = fmt.Errorf("MAXHANDS attribute on queue manager needs increasing. Current value = %d. Recommended minimum based on number of monitored queues = %d", ci.si.maxHandles, recommendedHandles)
			}
		}
	}

	// Subscribe to all of the various topics
	if err == nil {
		err = createSubscriptions()
	}

	// If you are using publications for some resource metrics, but have chosen not to collect the topics that might contain queue depth,
	// then there's still a possibility to find that particular value from QSTATUS responses as an alternative. The SubscriptionSelector has had
	// two topics, depending on the MQ version, which give the depth.
	subSel := dc.MonitoredQueues.SubscriptionSelector
	if subSel != "" && !strings.Contains(subSel, "GENERAL") && !strings.Contains(subSel, "GET") {
		logDebug("Setting connection to grab qdepth via QSTATUS")
		ci.useDepthFromStatus = true
	} else {
		logDebug("Setting connection to grab qdepth via Publication")
		ci.useDepthFromStatus = false
	}

	traceExitErr("discoverAndSubscribe", 0, err)

	return err
}

func discoverClasses(dc DiscoverConfig, metaPrefix string) error {
	var data []byte
	//var sub ibmmq.MQObject
	var mqtd *MQTopicDescriptor
	var metaReplyQObj ibmmq.MQObject
	var err error
	var rootTopic string

	traceEntry("discoverClasses")
	k := GetConnectionKey()
	ci := getConnection(k)

	// Have to know the starting point for the topic that tells about classes
	if metaPrefix == "" {
		rootTopic = "$SYS/MQ/INFO/QMGR/" + ci.si.resolvedQMgrName + "/Monitor/METADATA/CLASSES"
	} else {
		rootTopic = metaPrefix + "/INFO/QMGR/" + ci.si.resolvedQMgrName + "/Monitor/METADATA/CLASSES"
	}
	mqtd, err = subscribeManaged(rootTopic, &metaReplyQObj)
	if err == nil {
		data, err = getMessageWithHObj(true, metaReplyQObj)
		defer metaReplyQObj.Close(0)
		defer mqtd.unsubscribe()

		elemList, _ := parsePCFResponse(data)

		for i := 0; i < len(elemList); i++ {
			if elemList[i].Type != ibmmq.MQCFT_GROUP {
				continue
			}
			group := elemList[i]
			cl := new(MonClass)
			classIndex := 0
			cl.Types = make(map[int]*MonType)
			cl.Parent = GetPublishedMetrics(k)

			for j := 0; j < len(group.GroupList); j++ {
				elem := group.GroupList[j]
				switch elem.Parameter {
				case ibmmq.MQIAMO_MONITOR_CLASS:
					classIndex = int(elem.Int64Value[0])
				case ibmmq.MQIAMO_MONITOR_FLAGS:
					cl.flags = int(elem.Int64Value[0])
				case ibmmq.MQCAMO_MONITOR_CLASS:
					cl.Name = elem.String[0]
				case ibmmq.MQCAMO_MONITOR_DESC:
					cl.Description = elem.String[0]
				case ibmmq.MQCA_TOPIC_STRING:
					cl.typesTopic = elem.String[0]
				default:
					e2 := fmt.Errorf("Unknown parameter %d in class discovery", elem.Parameter)
					traceExitErr("discoverClasses", 1, e2)
					return e2
				}
			}

			if includeClass(dc, cl.Name) {
				cl.Parent.Classes[classIndex] = cl
			}
		}
	}

	ci.si.subsOpened = true
	traceExitErr("discoverClasses", 0, err)
	return err
}

func discoverTypes(dc DiscoverConfig, cl *MonClass) error {
	var data []byte
	var mqtd *MQTopicDescriptor
	var metaReplyQObj ibmmq.MQObject
	var err error

	traceEntry("discoverTypes")

	mqtd, err = subscribeManaged(cl.typesTopic, &metaReplyQObj)
	if err == nil {
		data, err = getMessageWithHObj(true, metaReplyQObj)
		defer metaReplyQObj.Close(0)
		defer mqtd.unsubscribe()

		elemList, _ := parsePCFResponse(data)

		for i := 0; i < len(elemList); i++ {
			if elemList[i].Type != ibmmq.MQCFT_GROUP {
				continue
			}

			group := elemList[i]
			ty := new(MonType)
			ty.Elements = make(map[int]*MonElement)
			ty.subHobj = make(map[string]*MQTopicDescriptor)

			typeIndex := 0
			ty.Parent = cl

			for j := 0; j < len(group.GroupList); j++ {
				elem := group.GroupList[j]
				switch elem.Parameter {

				case ibmmq.MQIAMO_MONITOR_TYPE:
					typeIndex = int(elem.Int64Value[0])
				case ibmmq.MQCAMO_MONITOR_TYPE:
					ty.Name = elem.String[0]
				case ibmmq.MQCAMO_MONITOR_DESC:
					ty.Description = elem.String[0]
				case ibmmq.MQCA_TOPIC_STRING:
					ty.elementTopic = elem.String[0]
				default:
					e2 := fmt.Errorf("Unknown parameter %d in type discovery", elem.Parameter)
					traceExitErr("discoverTypes", 1, e2)
					return e2
				}
			}
			if ty.Parent.Name == "STATQ" && dc.MonitoredQueues.SubscriptionSelector != "" {
				if strings.Contains(dc.MonitoredQueues.SubscriptionSelector, ty.Name) {
					if includeType(dc, ty.Name) {
						cl.Types[typeIndex] = ty
					}
				} else {
					logDebug("Not subscribing to Class STATQ Type %s resources", ty.Name)
				}
			} else {
				if includeType(dc, ty.Name) {
					cl.Types[typeIndex] = ty
				}
			}
		}
	}

	traceExitErr("discoverTypes", 0, err)
	return err
}

func discoverElements(dc DiscoverConfig, ty *MonType) error {
	var err error
	var data []byte
	var mqtd *MQTopicDescriptor
	var metaReplyQObj ibmmq.MQObject
	var elem *MonElement

	traceEntry("discoverElements")

	k := GetConnectionKey()
	ci := getConnection(k)

	mqtd, err = subscribeManaged(ty.elementTopic, &metaReplyQObj)
	if err == nil {
		data, err = getMessageWithHObj(true, metaReplyQObj)
		defer metaReplyQObj.Close(0)
		defer mqtd.unsubscribe()

		elemList, _ := parsePCFResponse(data)

		for i := 0; i < len(elemList); i++ {

			if elemList[i].Type == ibmmq.MQCFT_STRING && elemList[i].Parameter == ibmmq.MQCA_TOPIC_STRING {
				ty.ObjectTopic = elemList[i].String[0]
				continue
			}

			if elemList[i].Type != ibmmq.MQCFT_GROUP {
				continue
			}

			group := elemList[i]

			elem = new(MonElement)
			elementIndex := 0
			elem.Parent = ty
			elem.Values = make(map[string]int64)

			for j := 0; j < len(group.GroupList); j++ {
				e := group.GroupList[j]
				switch e.Parameter {

				case ibmmq.MQIAMO_MONITOR_ELEMENT:
					elementIndex = int(e.Int64Value[0])
				case ibmmq.MQIAMO_MONITOR_DATATYPE:
					elem.Datatype = int32(e.Int64Value[0])
				case ibmmq.MQCAMO_MONITOR_DESC:
					elem.Description = e.String[0]
				default:
					e2 := fmt.Errorf("Unknown parameter %d in type discovery", e.Parameter)
					traceExitErr("discoverElements", 1, e2)
					return e2
				}
			}

			elem.MetricName = formatDescription(elem)
			if includeElem(ci, elem, true) {
				ty.Elements[elementIndex] = elem
			}
		}
	}

	traceExitErr("discoverElements", 0, err)

	return err
}

// Rerun the subscription for elements, but this time adding a locale into the topic
// so that we can get the translated description. It's up to the collector program to
// then make use of that description.
func discoverElementsNLS(dc DiscoverConfig, ty *MonType, locale string) error {
	var err error
	var data []byte
	var mqtd *MQTopicDescriptor
	var metaReplyQObj ibmmq.MQObject

	traceEntry("discoverElementsNLS")
	if locale == "" {
		traceExit("discoverElementsNLS", 1)
		return nil
	}

	mqtd, err = subscribeManaged(ty.elementTopic+"/"+locale, &metaReplyQObj)
	if err == nil {
		// Don't wait - if there's nothing on that topic, then get out fast
		data, err = getMessageWithHObj(false, metaReplyQObj)
		metaReplyQObj.Close(0)
		mqtd.unsubscribe()

		if err != nil {
			mqreturn := err.(*ibmmq.MQReturn)
			if mqreturn.MQRC == ibmmq.MQRC_NO_MSG_AVAILABLE {
				err = nil
			}
		}

		elemList, _ := parsePCFResponse(data)

		for i := 0; i < len(elemList); i++ {

			if elemList[i].Type == ibmmq.MQCFT_STRING && elemList[i].Parameter == ibmmq.MQCA_TOPIC_STRING {
				continue
			}

			if elemList[i].Type != ibmmq.MQCFT_GROUP {
				continue
			}

			group := elemList[i]
			description := ""
			elementIndex := 0

			for j := 0; j < len(group.GroupList); j++ {
				e := group.GroupList[j]
				switch e.Parameter {

				case ibmmq.MQIAMO_MONITOR_ELEMENT:
					elementIndex = int(e.Int64Value[0])

				case ibmmq.MQCAMO_MONITOR_DESC:
					description = e.String[0]

				}
			}

			if description != "" {
				elem, ok := ty.Elements[elementIndex]
				if ok {
					elem.DescriptionNLS = description
				}

			}
		}
	}

	traceExitErr("discoverElementsNLS", 0, err)

	return err
}

/*
Discover the complete set of available statistics in the queue manager
by working through the classes, types and individual elements.

Then discover the list of individual queues we have been asked for.
*/
func discoverStats(dc DiscoverConfig) error {
	var err error

	traceEntry("discoverStats")
	k := GetConnectionKey()
	ci := getConnection(k)
	metrics := GetPublishedMetrics(k)

	metaPrefix := dc.MetaPrefix
	// Start with an empty set of information about the available stats
	metrics.Classes = make(map[int]*MonClass)

	// Allow us to proceed on z/OS even though it does not support pub/sub resources
	if metaPrefix == "" && !ci.usePublications {
		traceExit("discoverStats", 1)
		return nil
	}

	// Then get the list of CLASSES
	err = discoverClasses(dc, metaPrefix)

	// For each CLASS, discover the TYPEs of data available
	if err == nil {
		for _, cl := range metrics.Classes {
			err = discoverTypes(dc, cl)
			// And for each CLASS, discover the actual statistics elements
			if err == nil {
				for _, ty := range cl.Types {
					err = discoverElements(dc, ty)
					if err == nil && locale != "" {
						err = discoverElementsNLS(dc, ty, locale)
					}
				}
			}
		}

		// Validate all discovered metric names are unique
		// Need to add in if it's qmgr or q level
		nameSet := make(map[string]struct{})
		var exists = struct{}{}
		for _, cl := range metrics.Classes {
			for _, ty := range cl.Types {
				for _, elem := range ty.Elements {
					name := elem.MetricName
					if strings.Contains(ty.ObjectTopic, "%s") {
						switch cl.Name {
						case "NHAREPLICA":
							name = "nha_" + name
						default:
							name = "object_" + name
						}
					}
					if _, ok := nameSet[name]; ok {
						err = fmt.Errorf("Non-unique metric description '%s'", elem.MetricName)
					} else {
						if includeElem(ci, elem, true) {
							nameSet[name] = exists
						}
					}
				}
			}
		}

	}

	traceExitErr("discoverStats", 0, err)

	return err
}

/*
discoverQueues lists the queues that match all of the configured
patterns.

The patterns must match the MQ rule - asterisk on the end of the
string only.

If a bad pattern is used, or no queues exist that match the pattern
then an error is reported but we continue processing other patterns.

An alternative would be to list ALL the queues (though that could be a long list),
and then use a more general regexp match. Something for a later update perhaps.
*/
func discoverQueues(monitoredQueuePatterns string) error {
	var err error
	var qList []string
	var allQueues []string
	usingRegExp := false

	traceEntry("discoverQueues")
	ci := getConnection(GetConnectionKey())

	// If the list of monitored queues has a ! somewhere in it, we will
	// get the full list of queues on the qmgr, and filter it by patterns.
	if strings.Contains(monitoredQueuePatterns, "!") {
		usingRegExp = true
	}

	// A valid pattern list looks like
	//    !A*, !SYSTEM*, B*, DEV.QUEUE.1
	// If we know there are no exclusion patterns, then use the
	// set directly as it is more efficient
	if usingRegExp {
		allQueues, err = inquireObjects("*", ibmmq.MQOT_Q)
		if err == nil {
			qList = FilterRegExp(monitoredQueuePatterns, allQueues)
		}
	} else {
		qList, err = inquireObjects(monitoredQueuePatterns, ibmmq.MQOT_Q)
	}

	ci.localSlashWarning = false
	if len(qList) > 0 {
		//fmt.Printf("Monitoring Queues: %v\n", qList)
		for i := 0; i < len(qList); i++ {
			var qInfoElem *ObjInfo
			var ok bool
			qName := strings.TrimSpace(qList[i])

			// If the qName contains a '/' - eg "DEV/QUEUE/1" then the queue manager cannot
			// process resource publications by simply inserting the qName because it disrupts
			// the topic string pattern. This was fixed in the queue manager by 9.3.0 by allowing
			// the subscriptions to use '&' in place of the '/' character.
			//
			// For older levels of MQ, because of the possible complexities of pattern matching, we don't
			// actually fail the discovery process, but instead issue a warning and continue with
			// other queues.
			if strings.Contains(qName, "/") && ci.globalSlashWarning && GetCommandLevel() < ibmmq.MQCMDL_LEVEL_930 {
				ci.localSlashWarning = true // First time through, issue the warning for all queues
				logError("Warning: Cannot subscribe to queue containing '/': %s", qName)
				continue
			}

			if qInfoElem, ok = qInfoMap[qName]; !ok {
				qInfoElem = new(ObjInfo)
			}
			qInfoElem.AttrMaxDepth = defaultMaxQDepth
			qInfoElem.exists = true
			qInfoMap[qName] = qInfoElem
		}

		if ci.useStatus {
			if usingRegExp {
				for qName, _ := range qInfoMap {
					if len(qName) > 0 {
						inquireQueueAttributes(qName)
					}
				}
			} else {
				inquireQueueAttributes(monitoredQueuePatterns)
			}
		}

		if ci.localSlashWarning {
			ci.globalSlashWarning = true
		}

		if err != nil {
			//fmt.Printf("Queue Discovery Error: %v\n", err)
		}
		traceExit("discoverQueues", 1)

		return nil
	}

	traceExitErr("discoverQueues", 0, err)

	return err
}

func inquireObjects(objectPatternsList string, objectType int32) ([]string, error) {
	return inquireObjectsWithFilter(objectPatternsList, objectType, 0)
}
func inquireObjectsWithFilter(objectPatternsList string, objectType int32, filterType int32) ([]string, error) {

	var err error
	var elem *ibmmq.PCFParameter
	var datalen int
	var objectList []string
	var command int32
	var attribute int32
	var returnedAttribute int32
	var missingPatterns string

	traceEntryF("inquireObjects", "Type: %d Patterns: %s", objectType, objectPatternsList)
	ci := getConnection(GetConnectionKey())

	objectList = make([]string, 0)

	if objectPatternsList == "" {
		traceExitErr("inquireObjects", 1, err)
		return nil, err
	}

	statusClearReplyQ()

	objectPatterns := strings.Split(strings.TrimSpace(objectPatternsList), ",")
	for i := 0; i < len(objectPatterns) && err == nil; i++ {
		var buf []byte
		pattern := strings.TrimSpace(objectPatterns[i])
		if len(pattern) == 0 {
			continue
		}

		if strings.Count(pattern, "*") > 1 ||
			(strings.Count(pattern, "*") == 1 && !strings.HasSuffix(pattern, "*")) {
			return nil, fmt.Errorf("Object pattern '%s' is not valid", pattern)
		}

		switch objectType {
		case ibmmq.MQOT_Q:
			command = ibmmq.MQCMD_INQUIRE_Q_NAMES
			attribute = ibmmq.MQCA_Q_NAME
			returnedAttribute = ibmmq.MQCACF_Q_NAMES
		case ibmmq.MQOT_CHANNEL:
			command = ibmmq.MQCMD_INQUIRE_CHANNEL_NAMES
			attribute = ibmmq.MQCACH_CHANNEL_NAME
			returnedAttribute = ibmmq.MQCACH_CHANNEL_NAMES
		default:
			e2 := fmt.Errorf("Object type %d is not valid", objectType)
			traceExitErr("inquireObjects", 2, e2)
			return nil, e2
		}

		putmqmd := ibmmq.NewMQMD()
		pmo := ibmmq.NewMQPMO()

		pmo.Options = ibmmq.MQPMO_NO_SYNCPOINT
		pmo.Options |= ibmmq.MQPMO_NEW_MSG_ID
		pmo.Options |= ibmmq.MQPMO_NEW_CORREL_ID
		pmo.Options |= ibmmq.MQPMO_FAIL_IF_QUIESCING

		putmqmd.Format = "MQADMIN"
		putmqmd.ReplyToQ = ci.si.statusReplyQObj.Name
		putmqmd.MsgType = ibmmq.MQMT_REQUEST
		putmqmd.Report = ibmmq.MQRO_PASS_DISCARD_AND_EXPIRY

		cfh := ibmmq.NewMQCFH()
		cfh.Version = ibmmq.MQCFH_VERSION_3
		cfh.Type = ibmmq.MQCFT_COMMAND_XR

		// Can allow all the other fields to default
		cfh.Command = command

		// Add the parameters one at a time into a buffer
		pcfparm := new(ibmmq.PCFParameter)
		pcfparm.Type = ibmmq.MQCFT_STRING
		pcfparm.Parameter = attribute
		pcfparm.String = []string{pattern}
		cfh.ParameterCount++
		buf = append(buf, pcfparm.Bytes()...)

		if command == ibmmq.MQCMD_INQUIRE_Q_NAMES {
			pcfparm = new(ibmmq.PCFParameter)
			pcfparm.Type = ibmmq.MQCFT_INTEGER
			pcfparm.Parameter = ibmmq.MQIA_Q_TYPE
			pcfparm.Int64Value = []int64{int64(ibmmq.MQQT_LOCAL)}
			cfh.ParameterCount++
			buf = append(buf, pcfparm.Bytes()...)

			// We don't see shared queues in the returned set unless explicitly asked for.
			// MQQSGD_ALL returns all locals, and (if qmgr in a QSG) also shared queues.
			if ci.si.platform == ibmmq.MQPL_ZOS {
				pcfparm = new(ibmmq.PCFParameter)
				pcfparm.Type = ibmmq.MQCFT_INTEGER
				pcfparm.Parameter = ibmmq.MQIA_QSG_DISP
				pcfparm.Int64Value = []int64{int64(ibmmq.MQQSGD_ALL)}
				cfh.ParameterCount++
				buf = append(buf, pcfparm.Bytes()...)
			}
		}

		if command == ibmmq.MQCMD_INQUIRE_CHANNEL_NAMES && filterType != 0 {
			// Need to be prepared to get an error either of "no names" or "command not available"
			// Add CHLTYPE(AMQP|MQTT)
			pcfparm = new(ibmmq.PCFParameter)
			pcfparm.Type = ibmmq.MQCFT_INTEGER
			pcfparm.Parameter = ibmmq.MQIACH_CHANNEL_TYPE
			pcfparm.Int64Value = []int64{int64(ibmmq.MQCHT_AMQP)}
			cfh.ParameterCount++
			buf = append(buf, pcfparm.Bytes()...)
		}

		// Once we know the total number of parameters, put the
		// CFH header on the front of the buffer.
		buf = append(cfh.Bytes(), buf...)

		// And put the command to the queue
		err = ci.si.cmdQObj.Put(putmqmd, pmo, buf)

		if err != nil {
			traceExitErr("inquireObjects", 3, err)
			return objectList, err
		}

		// Use a loop to make sure we're looking at the proper response from a
		// z/OS queue manager using the MQCFT_XR mechanism. There is a 2ary loop
		// inside getWithoutTruncation to try to get a complete message
		for xr := true; xr; {
			buf, datalen, err = getWithoutTruncation(ci.si.statusReplyQObj)
			//logTrace("Buf starts %v",buf[0:128])
			if err == nil {
				cfh, offset := ibmmq.ReadPCFHeader(buf)
				if cfh.CompCode != ibmmq.MQCC_OK {
					xr = false
					return objectList, fmt.Errorf("PCF command %s [%d] failed with CC %s [%d] RC %s [%d]",
						ibmmq.MQItoString("CMD", int(cfh.Command)), cfh.Command,
						ibmmq.MQItoString("CC", int(cfh.CompCode)), cfh.CompCode,
						ibmmq.MQItoString("RC", int(cfh.Reason)), cfh.Reason)
				} else {
					logTrace("Received response of type %d [%s] and length %d", cfh.Type, ibmmq.MQItoString("CFT", int(cfh.Type)), datalen)
					if ci.si.platform == ibmmq.MQPL_ZOS && cfh.Type != ibmmq.MQCFT_XR_ITEM {
						continue
					}
					xr = false
					parmAvail := true
					bytesRead := 0
					if cfh.ParameterCount == 0 {
						parmAvail = false
						missingPatterns = missingPatterns + " " + pattern
					}

					for parmAvail && cfh.CompCode != ibmmq.MQCC_FAILED {
						elem, bytesRead = ibmmq.ReadPCFParameter(buf[offset:])
						offset += bytesRead
						// Have we now reached the end of the message
						if offset >= datalen {
							parmAvail = false
						}

						switch elem.Parameter {
						case returnedAttribute:
							logTrace("Number of returned strings = %d", len(elem.String))

							if len(elem.String) == 0 {
								missingPatterns = missingPatterns + " " + pattern
							}
							for i := 0; i < len(elem.String); i++ {
								s := strings.TrimSpace(elem.String[i])
								objectList = append(objectList, s)
							}
						}
					}
				}
			} else {
				traceExitErr("inquireObjects", 4, err)
				return objectList, err
			}
		}

	}

	if len(missingPatterns) > 0 && err == nil {
		err = fmt.Errorf("No objects matching %s of type %d exist", missingPatterns, objectType)
	}
	traceExitErr("inquireObjects", 0, err)
	return objectList, err
}

/*
Now that we know which topics can return data, need to
create all the subscriptions.
*/
func createSubscriptions() error {
	var err error
	var mqtd *MQTopicDescriptor

	usingDurableSubs := false

	traceEntry("createSubscriptions")
	k := GetConnectionKey()
	ci := getConnection(GetConnectionKey())
	metrics := GetPublishedMetrics(k)

	if ci.durableSubPrefix != "" {
		usingDurableSubs = true
	}

	for _, cl := range metrics.Classes {
		for _, ty := range cl.Types {
			// For queues, we use the list of discovered objects to
			// create the subscriptions. For other object types, the list
			// is allowed to be a wildcard. In particular, the NativeHA instances
			if strings.Contains(ty.ObjectTopic, "%s") {
				im := qInfoMap
				switch cl.Name {
				case "NHAREPLICA":
					im = nhaInfoMap
				}
				for key, _ := range im {
					if len(key) == 0 {
						continue
					}

					// See if we've already got a subscription
					// for this object. I
					if s, ok := ty.subHobj[key]; ok {
						if im[key].exists {
							// leave alone
						} else {
							topic := s.topic
							logDebug("Closing subscription %+v %s for %s", s, topic, key)
							s.unsubscribe()
							delete(ty.subHobj, key)
						}
					} else {
						// Convert embedded "/" to "&" in the topic subscriptions, provided
						// we are at MQ 9.3. The maps referring to the topic still keep the "/" in
						// the key for maps referring to the object; we don't need the modified topic name
						// outside of the initial subscription.
						keyDeslashed := key
						if GetCommandLevel() >= ibmmq.MQCMDL_LEVEL_930 {
							keyDeslashed = strings.Replace(key, "/", "&", -1)
						}
						topic := fmt.Sprintf(ty.ObjectTopic, keyDeslashed)
						if usingDurableSubs {
							mqtd, err = subscribeDurable(topic, &ci.si.replyQObj)
						} else {
							mqtd, err = subscribe(topic, &ci.si.replyQObj)
						}
						if err == nil {
							ty.subHobj[key] = mqtd
							im[key].firstCollection = true
						}
					}
				}
			} else {
				if _, ok := ty.subHobj[QMgrMapKey]; !ok {

					// Don't have a qmgr-level subscription to this topic. Should
					// only do this subscription once at startup
					mqtd, err = subscribe(ty.ObjectTopic, &ci.si.replyQObj)
					ty.subHobj[QMgrMapKey] = mqtd
				}
			}

			if err != nil {
				e2 := fmt.Errorf("Error subscribing to %s: %v", ty.ObjectTopic, err)
				traceExitErr("createSubscriptions", 1, e2)
				return e2
			}
		}
	}

	traceExitErr("createSubscriptions", 0, err)

	return err
}

/*
ProcessPublications has to read all of the messages since the last scrape
and update the values for every relevant gauge.

Because the generation of the messages by the qmgr, and being told to
read them by the main loop, may not have identical frequencies, there may be
cases where multiple pieces of data have to be collated for the same
gauge. Conversely, there may be times when this is called but there
are no metrics to update.
*/
func ProcessPublications() error {
	var err error
	var data []byte

	var objName string
	var objType int32
	var classidx int
	var typeidx int
	var elementidx int
	var value int64

	traceEntry("ProcessPublications")

	k := GetConnectionKey()
	ci := getConnection(k)
	metrics := GetPublishedMetrics(k)
	ci.publicationCount = 0

	if !ci.usePublications {
		traceExit("ProcessPublications", 1)
		return nil
	}

	// Keep reading all available messages until queue is empty. Don't
	// do a GET-WAIT; just immediate removals.
	for err == nil {
		data, err = getMessage(ci, false)

		// Most common error will be MQRC_NO_MESSAGE_AVAILABLE
		// which will end the loop.
		if err == nil {
			ci.publicationCount++
			elemList, _ := parsePCFResponse(data)

			// A typical publication contains some fixed
			// headers (qmgrName, objectName, class, type etc)
			// followed by a list of index/values.
			// Start with an empty map for each message
			values := make(map[int]int64)

			objName = ""

			for i := 0; i < len(elemList); i++ {
				switch elemList[i].Parameter {
				case ibmmq.MQCA_Q_MGR_NAME:
					_ = strings.TrimSpace(elemList[i].String[0])
				case ibmmq.MQCA_Q_NAME:
					objName = strings.TrimSpace(elemList[i].String[0])
					objType = ibmmq.MQOT_Q
				case ibmmq.MQCA_TOPIC_NAME:
					objName = strings.TrimSpace(elemList[i].String[0])
					objType = ibmmq.MQOT_TOPIC
				case ibmmq.MQIACF_OBJECT_TYPE:
					// May need to use this as part of the object key and
					// labelling But for now we can ignore it.
					_ = ibmmq.MQItoString("OT", int(elemList[i].Int64Value[0]))
				case ibmmq.MQCACF_NHA_INSTANCE_NAME:
					// We have either the instance name or the group name in the response
					objName = strings.TrimSpace(elemList[i].String[0])
					objType = OT_NHA
				case ibmmq.MQCACF_NHA_GROUP_NAME:
					objName = strings.TrimSpace(elemList[i].String[0])
					objType = OT_NHA
				case ibmmq.MQIAMO_MONITOR_CLASS:
					classidx = int(elemList[i].Int64Value[0])
				case ibmmq.MQIAMO_MONITOR_TYPE:
					typeidx = int(elemList[i].Int64Value[0])
				case ibmmq.MQIAMO64_MONITOR_INTERVAL:
					_ = elemList[i].Int64Value[0]
				case ibmmq.MQIAMO_MONITOR_FLAGS:
					_ = int(elemList[i].Int64Value[0])
				default:
					if len(elemList[i].Int64Value) > 0 {
						value = elemList[i].Int64Value[0]
						elementidx = int(elemList[i].Parameter)
						values[elementidx] = value
					} else {
						logDebug("Unparsed element: %+v", elemList[i])
					}
				}
			}

			// Now have all the values in this particular message
			// Have to incorporate them into any that already exist.
			//
			// Each element contains a map holding all the objects
			// touched by these messages. The map is referenced by
			// object name if it's a queue; for qmgr-level stats, the
			// map only needs to contain a single entry which I've
			// chosen to reference by "@self" which can never be a
			// real queue name.
			//
			// We have to know whether to need to add the values
			// contained from multiple publications that might
			// have arrived in the scrape interval
			// for the same resource, or whether we should just
			// overwrite with the latest. Although there are
			// several monitor Datatypes, all of them apart from
			// explicitly labelled "DELTA" are ones we should just
			// use the latest value.
			for key, newValue := range values {

				typesArray := metrics.Classes[classidx].Types
				if typesIdx, ok1 := typesArray[typeidx]; ok1 {
					if elem, ok2 := typesIdx.Elements[key]; ok2 {
						objectName := objName
						elemKey := ""
						if objectName == "" {
							elemKey = QMgrMapKey
						} else {
							// If we've unsubscribed and resubscribed to the same queue (unusual
							// but a dynamic resub nature may permit that) then discard the first metric
							// from a queue in case it's got a running total instead of the last interval.
							objectInfoMap := qInfoMap
							if objType == ibmmq.MQOT_Q {
								objectInfoMap = qInfoMap
								elemKey = objectName
							} else if objType == OT_NHA {
								// The objectname is EITHER the group name (for RECOVERY metrics)
								// or the instance name (for REPLICATION metrics)
								objectInfoMap = nhaInfoMap
								elemKey = NativeHAKeyPrefix + objName
							}
							if qi, ok := objectInfoMap[objName]; ok {
								if qi.firstCollection {
									continue
								}
								if !qi.exists && objType != OT_NHA {
									//logDebug("Data for untracked object %s being ignored", objName)
									continue
								}
							} else {
								// There is no discovery/validation of instance names needed for NHA - we
								// always add it to the map
								if objType != OT_NHA {
									//logDebug("Data for unknown object %s being ignored", objName)
									continue
								}
							}
						}

						if oldValue, ok := elem.Values[elemKey]; ok {
							if elem.Datatype == ibmmq.MQIAMO_MONITOR_DELTA {
								//logDebug("Metric with delta flag on  - %s", elem.MetricName)
								value = oldValue + newValue
							} else {
								//logDebug("Metric with delta flag off - %s", elem.MetricName)
								value = newValue
							}
						} else {
							value = newValue
						}

						if includeElem(ci, elem, false) {
							elem.Values[elemKey] = value
						}
					}
				}
			}
		} else {
			// err != nil
			mqreturn := err.(*ibmmq.MQReturn)

			if mqreturn.MQCC == ibmmq.MQCC_FAILED && mqreturn.MQRC != ibmmq.MQRC_NO_MSG_AVAILABLE {
				traceExitErr("ProcessPublications", 2, mqreturn)
				return mqreturn
			}
		}
	}

	// Ensure that all known queues are marked as having had at least one collection cycle
	for _, qi := range qInfoMap {
		qi.firstCollection = false
	}

	traceExit("ProcessPublications", 0)
	return nil
}

// The STATAPP metrics are not very useful as they only work for apps known at subscription
// time. As well as needing additional configuration.
// So we ignore these for now. Adding them to the subscription
// list by default would increase the handles in use without benefit.
func includeClass(dc DiscoverConfig, cl string) bool {
	rc := true
	if cl == "STATAPP" {
		rc = false
	}
	return rc
}

// A STATQ/EXTENDED block of metrics is available on some versions of MQ
// that are really intended for use by L2/L3 service. So we exclude them
// unless explicitly requested in the SubscriptionSelector config
func includeType(dc DiscoverConfig, t string) bool {
	rc := true

	if t != "" && t == "EXTENDED" {
		if dc.MonitoredQueues.SubscriptionSelector == "" {
			logDebug("Not subscribing to Class STATQ Type %s resources", t)
			rc = false
		} else if !strings.Contains(dc.MonitoredQueues.SubscriptionSelector, t) {
			logDebug("Not subscribing to Class STATQ Type %s resources", t)
			rc = false
		}
	}

	return rc
}

// This deals with situations where metrics have been added to the published elements
// but duplicate values elsewhere. We will exclude them if we are already collecting them
// through that other mechanism. Currently just 2 items are expected to need this rule.
// This is called after any metric description/name mapping rules have been processed, so the metric name
// is the converted string.
//
// Older versions of the collectors will not know to exclude the duplicate, but they will also not know
// the mapped metric name. So they will emit both the QSTATS versions and the new duplicate metric but with
// different names. Which might be confusing for anyone looking to build a new dashboard panel, but not
// a fatal error.
//
// This is needed from MQ 9.4.2 onwards, and from various fixpack levels on 9.2 and 9.3 where the system
// topic metrics were extended
var excludeMetric = map[string]bool{
	"input_handles":  true,
	"output_handles": true,
}

func includeElem(ci *connectionInfo, elem *MonElement, discovering bool) bool {
	rc := true

	_, found := excludeMetric[elem.MetricName]
	if found {
		// We prefer to use the value from the DIS QSTATUS command as that is available everywhere, in all
		// versions. The published metric is only available in a subset of versions.
		if ci.useStatus {
			// Only print this message during the discovery phase so we don't overwhelm the debug log
			if discovering {
				logDebug("Not including Class %s Type %s Element %s (already available elsewhere)", elem.Parent.Parent.Name, elem.Parent.Name, elem.MetricName)
			}
			rc = false

		}
	}
	return rc
}

/*
Parse a PCF response message, returning the
elements. If an element represents a PCF group, that element
has the pieces of the group attached to itself. While
it is theoretically possible for groups to contain groups, MQ never
does that, so the code here does not need to recurse through multiple
levels.

Returns TRUE if this is the last response in a
set, based on the MQCFH.Control value.
*/
func parsePCFResponse(buf []byte) ([]*ibmmq.PCFParameter, bool) {
	var elem *ibmmq.PCFParameter
	var elemList []*ibmmq.PCFParameter
	var bytesRead int

	traceEntry("parsePCFResponse")

	rc := false

	// First get the MQCFH structure. This also returns
	// the number of bytes read so we know where to start
	// looking for the next element
	cfh, offset := ibmmq.ReadPCFHeader(buf)
	if cfh == nil {
		traceExit("parsePCFResponse", 1)
		return elemList, true
	}

	// If the command succeeded, loop through the remainder of the
	// message to decode each parameter.
	for i := 0; i < int(cfh.ParameterCount); i++ {
		// We don't know how long the next parameter is, so we just
		// pass in "from here to the end" and let the parser
		// tell us how far it got.
		// We understand PCF Groups in ReadPCFParameter so don't need to extract them explicitly
		elem, bytesRead = ibmmq.ReadPCFParameter(buf[offset:])
		offset += bytesRead

		elemList = append(elemList, elem)
	}

	if cfh.Control == ibmmq.MQCFC_LAST {
		rc = true
	}
	traceExit("parsePCFResponse", 0)

	return elemList, rc
}

/*
ReadPatterns is called during the initial configuration step to read a file
containing object name patterns if they are not explicitly given
on the command line.
*/
func ReadPatterns(f string) (string, error) {
	var s string

	file, err := os.Open(f)
	if err != nil {
		return "", fmt.Errorf("Error Opening file %s: %v", f, err)
	}
	defer file.Close()
	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		if s != "" {
			s += ","
		}
		s += scanner.Text()
	}
	if err := scanner.Err(); err != nil {
		return "", fmt.Errorf("Error Reading from %s: %v", f, err)
	}

	return s, nil
}

/*
Normalise converts the value returned from MQ into the correct units
such as converting MB to bytes.
*/
func Normalise(elem *MonElement, key string, value int64) float64 {
	f := float64(value)
	// I've  seen negative numbers which are nonsense,
	// possibly 32-bit overflow or uninitialised values
	// in the qmgr. So force data to something sensible
	// just in case those were due to a bug.
	if f < 0 {
		f = 0
	}

	// Convert suitable metrics to base units
	if elem.Datatype == ibmmq.MQIAMO_MONITOR_PERCENT ||
		elem.Datatype == ibmmq.MQIAMO_MONITOR_HUNDREDTHS {
		f = f / 100
	} else if elem.Datatype == ibmmq.MQIAMO_MONITOR_MB {
		f = f * 1024 * 1024
	} else if elem.Datatype == ibmmq.MQIAMO_MONITOR_GB {
		f = f * 1024 * 1024 * 1024
	} else if elem.Datatype ==
		ibmmq.MQIAMO_MONITOR_MICROSEC {
		f = f / 1000000
	}

	return f
}

func VerifyPatterns(patternList string) error {
	return verifyObjectPatterns(patternList, false)
}
func VerifyQueuePatterns(patternList string) error {
	return verifyObjectPatterns(patternList, true)
}
func verifyObjectPatterns(patternList string, allowNegatives bool) error {
	var err error
	objectPatterns := strings.Split(patternList, ",")
	for i := 0; i < len(objectPatterns) && err == nil; i++ {

		pattern := strings.TrimSpace(objectPatterns[i])
		if pattern == "" {
			continue
		}
		if strings.Count(pattern, "*") > 1 ||
			(strings.Count(pattern, "*") == 1 && !strings.HasSuffix(pattern, "*")) {
			err = fmt.Errorf("Object pattern '%s' is not valid. '*' must be last character in a pattern", pattern)
		}
		// Will allow ! to be at the start of a pattern.
		if allowNegatives {
			if strings.Count(pattern, "!") > 1 ||
				(strings.Count(pattern, "!") == 1 && !strings.HasPrefix(pattern, "!")) {
				err = fmt.Errorf("Object pattern '%s' is not valid. '!' must be first character in a pattern", pattern)
			}
		}
	}
	return err
}

/*
Patterns are very simple, following normal MQ lines except that
they can be prefixed with "!" to exclude them. For example,

	"APP*,DEV*,!SYSTEM*"

I decided not to use a full regexp pattern matcher because it's not really
natural in the MQ world.

Rules for the pattern matching are:

	All positive implies NONE except listed names
	All negative implies ALL except listed names
	Mixed positive and negative entries is done in two phases:
	  Remove the negative patterns
	  Filter the remaining set with the positive patterns
	Allows patterns like "S*,!SYSTEM*" to still return S.1 but not SYSTEM.DEF.Q

A pattern like "!DEV*,DEV.QUEUE.1" has the negative element
given priority over the positive. So DEV.QUEUE.1 does not match here.
I could reverse the logic in the mixed model, but I think this is preferable.
*/
func FilterRegExp(patterns string, possibleList []string) []string {
	var excludeList []string
	var includeList []string
	var qList []string
	var include bool

	assumeAll := false
	mixed := false
	excludeListString := "" // Comma-separated strings rebuilt for recursive input to this function
	includeListString := ""

	objectPatterns := strings.Split(strings.TrimSpace(patterns), ",")
	for i := 0; i < len(objectPatterns); i++ {
		r := strings.TrimSpace(objectPatterns[i])
		if len(r) == 0 {
			continue
		}
		if strings.HasPrefix(r, "!") {
			// Build a list of patterns to exlude, removing the '!' prefix
			excludeList = append(excludeList, r[1:])
			if excludeListString == "" {
				excludeListString = r
			} else {
				excludeListString = excludeListString + "," + r

			}
		} else {
			includeList = append(includeList, r)
			if includeListString == "" {
				includeListString = r
			} else {
				includeListString = includeListString + "," + r
			}
		}
	}

	//fmt.Printf("  Include list: %v (%d)\n", includeList, len(includeList))
	//fmt.Printf("  Exclude list: %v (%d)\n", excludeList, len(excludeList))

	if len(includeList) > 0 && len(excludeList) == 0 { // all positive
		assumeAll = false
	} else if len(excludeList) > 0 && len(includeList) == 0 { // all negative
		assumeAll = true
	} else {
		assumeAll = true
		mixed = true // Will run a second filter pass
	}

	for j := 0; j < len(possibleList); j++ {
		s := strings.TrimSpace(possibleList[j])
		if len(s) == 0 {
			continue
		}

		if assumeAll {
			include = true
			for i := 0; i < len(excludeList); i++ {
				r := excludeList[i]
				if patternMatch(s, r) {
					include = false
				}
			}
		} else {
			include = false
			for i := 0; i < len(includeList); i++ {
				r := includeList[i]
				if patternMatch(s, r) {
					include = true
				}
			}
		}

		if include {
			qList = append(qList, s)
		} else {
			//fmt.Printf("Excluding %s\n", s)
		}
	}

	if mixed {
		//fmt.Printf("Calling again with patterns %s for %v\n", includeListString, qList)
		qList = FilterRegExp(includeListString, qList)
	}

	//fmt.Printf("Discovered qList = %v\n",qList)
	return qList
}

func patternMatch(s string, r string) bool {
	rc := false
	if strings.HasSuffix(r, "*") {
		if strings.HasPrefix(s, r[:len(r)-1]) {
			rc = true
		}
	} else if s == r {
		rc = true
	}

	//	fmt.Printf("Comparing %s with %s %v\n",s,r,rc)
	return rc
}

func GetObjectDescription(key string, objectType int32) string {
	var o *ObjInfo
	ok := false
	switch objectType {
	case ibmmq.MQOT_Q:
		o, ok = qInfoMap[key]
	case ibmmq.MQOT_CHANNEL:
		o, ok = chlInfoMap[key]
	case OT_CHANNEL_AMQP:
		o, ok = amqpInfoMap[key]
	case OT_Q_MGR:
		o = qMgrInfo
		ok = true
	}

	if !ok || strings.TrimSpace(o.Description) == "" {
		// return something so Prometheus doesn't turn it into "0.0"
		return DUMMY_STRING
	} else {
		return o.Description
	}
}

func trimToNull(s string) string {
	var rc string
	i := strings.IndexByte(s, 0)
	if i == -1 {
		rc = s
	} else {
		rc = s[0:i]
	}
	return strings.TrimSpace(rc)
}

// Return a complete message - if the default buffer is too small, iterate until
// we no longer get the MQRC_TRUNCATED_MSG_FAILED
func getWithoutTruncation(hObj ibmmq.MQObject) ([]byte, int, error) {
	var err error
	datalen := 0
	traceEntry("getWithoutTruncation")

	ci := getConnection(GetConnectionKey())

	if ci.si.statusReplyBuf == nil {
		// Pick a default initial size for this session's reply buffer. If it needs to grow, it will.
		// There's no shrinking done later though as the size is likely to remain needed for the
		// lifetime of the collector
		ci.si.statusReplyBuf = make([]byte, 32768)
	}

	for trunc := true; trunc; {
		// Now get the response. Reset the MD and GMO on each iteration to ensure we don't get mixed up
		// with anything that gets modified (like the CCSID) even on failed/truncated GETs.
		md := ibmmq.NewMQMD()
		gmo := ibmmq.NewMQGMO()
		gmo.Options = ibmmq.MQGMO_NO_SYNCPOINT
		gmo.Options |= ibmmq.MQGMO_FAIL_IF_QUIESCING
		gmo.Options |= ibmmq.MQGMO_WAIT
		gmo.Options |= ibmmq.MQGMO_CONVERT
		gmo.WaitInterval = 30 * 1000
		logTrace("getWithoutTruncation: Trying MQGET with buffer size %d gmo.Options %x md.ccsid %d", len(ci.si.statusReplyBuf), gmo.Options, md.CodedCharSetId)
		datalen, err = hObj.Get(md, gmo, ci.si.statusReplyBuf)
		if err != nil {
			mqreturn := err.(*ibmmq.MQReturn)
			if mqreturn.MQCC != ibmmq.MQCC_OK && mqreturn.MQRC == ibmmq.MQRC_TRUNCATED_MSG_FAILED && len(ci.si.statusReplyBuf) < maxBufSize {
				// Double the size, apart from capping it at 100MB
				ci.si.statusReplyBuf = append(ci.si.statusReplyBuf, make([]byte, len(ci.si.statusReplyBuf))...)
				if len(ci.si.statusReplyBuf) > maxBufSize {
					ci.si.statusReplyBuf = ci.si.statusReplyBuf[0:maxBufSize]
				}
			} else {
				traceExitF("getWithoutTruncation", 1, "BufSize %d Error %v", len(ci.si.statusReplyBuf), err)
				return ci.si.statusReplyBuf, datalen, err
			}
		} else {
			trunc = false
		}
	}

	traceExit("getWithoutTruncation", 0)
	return ci.si.statusReplyBuf, datalen, err
}

// Convert a string into something containing only valid UTF8 characters
func printableStringUTF8(s string) string {
	if utf8.ValidString(s) {
		return s
	} else {
		//logDebug("Fixing UTF for string %s",s)
		return strings.Map(fixUtf8, s)
	}
}

func fixUtf8(r rune) rune {
	if r == utf8.RuneError {
		return '.'
	}
	return r
}
